---
slug: "2019-06-01-IO-2019-a11y"
title:  "I/O 2019 and a11y"
date:   2019-05-31 19:42 +1100
categories: "blog"
---

import a11y from './images/a11y-2019.mp4';

# I/O 2019 and a11y

I care very much about making truly accessible apps, so naturally the first session for I/O â€˜19 I watched was â€œWhatâ€™s new in Android accessibility?â€ ğŸ± here are my key takeaways:

- Live Transcribe ğŸ“ is an app that adds captions - live, to any speech synthesised by the mic! When captions appear, the UX is amazingly accessible with high contrast, large text options available. [Live Transcribe](https://play.google.com/store/apps/detailsid=com.google.audio.hearing.visualization.accessibility.scribe)

- The a11y suite now ships with captioning for videos even in the photos app. This is possible through recurrent neural networks within your device - your data never leaves your phone! ğŸ¤–

- Talkbackâ€™s context menu now has a search option. This lets you jump to a cta or sub-section within the view rather than having to navigate the entire screen ğŸ“º [Accessibility Suite](https://play.google.com/store/apps/details?id=com.google.android.marvin.talkback)

- Voice access enhancements make a dotted overlay appear over your device so it can be controlled via voice, just like using Google assistant! ğŸ¤³ (bit experimental IMHO) [Voice Access](https://play.google.com/store/apps/details?id=com.google.android.apps.accessibility.voiceaccess)


<p align="center">
 <video width="30%" controls autostart autoPlay src={a11y} type="video/mp4" />
</p>